{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfLOnib2Oer4AP50KSuH7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himanshukunar/excelr-assignments/blob/main/Assignment18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpgtmvyhZEpY",
        "outputId": "4aed9326-099c-4c2c-a110-af142bd15925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape: (20000, 17)\n",
            "Column Names: Index(['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar', 'ybar',\n",
            "       'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge', 'xedgey',\n",
            "       'yedge', 'yedgex'],\n",
            "      dtype='object')\n",
            "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
            "0      T     2     8      3       5      1     8    13      0      6      6   \n",
            "1      I     5    12      3       7      2    10     5      5      4     13   \n",
            "2      D     4    11      6       8      6    10     6      2      6     10   \n",
            "3      N     7    11      6       6      3     5     9      4      6      4   \n",
            "4      G     2     1      3       1      1     8     6      6      6      6   \n",
            "\n",
            "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
            "0      10       8      0       8      0       8  \n",
            "1       3       9      2       8      4      10  \n",
            "2       3       7      3       7      3       9  \n",
            "3       4      10      6      10      2       8  \n",
            "4       5       9      1       7      5      10  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Alphabets_data.csv\")  # Use correct file name\n",
        "\n",
        "# Basic summary\n",
        "print(\"Data Shape:\", df.shape)\n",
        "print(\"Column Names:\", df.columns)\n",
        "print(df.head())\n",
        "\n",
        "# Handle missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('letter', axis=1)\n",
        "y = df['letter']\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Normalize feature data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Build basic ANN model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(26, activation='softmax')  # 26 classes for A-Z\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_labels))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqrFxHpsZif3",
        "outputId": "6104a3e5-6886-4be7-cc08-dee917af71fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2816 - loss: 2.6381 - val_accuracy: 0.6700 - val_loss: 1.3405\n",
            "Epoch 2/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6940 - loss: 1.2091 - val_accuracy: 0.7462 - val_loss: 0.9603\n",
            "Epoch 3/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7543 - loss: 0.9246 - val_accuracy: 0.7869 - val_loss: 0.8074\n",
            "Epoch 4/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7905 - loss: 0.7748 - val_accuracy: 0.8106 - val_loss: 0.7068\n",
            "Epoch 5/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8175 - loss: 0.6713 - val_accuracy: 0.8131 - val_loss: 0.6431\n",
            "Epoch 6/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.6265 - val_accuracy: 0.8300 - val_loss: 0.5884\n",
            "Epoch 7/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.5636 - val_accuracy: 0.8475 - val_loss: 0.5468\n",
            "Epoch 8/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.5146 - val_accuracy: 0.8519 - val_loss: 0.5110\n",
            "Epoch 9/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.4808 - val_accuracy: 0.8644 - val_loss: 0.4778\n",
            "Epoch 10/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.4605 - val_accuracy: 0.8625 - val_loss: 0.4602\n",
            "Epoch 11/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.4324 - val_accuracy: 0.8737 - val_loss: 0.4320\n",
            "Epoch 12/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.4050 - val_accuracy: 0.8794 - val_loss: 0.4119\n",
            "Epoch 13/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.3837 - val_accuracy: 0.8769 - val_loss: 0.3996\n",
            "Epoch 14/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.3710 - val_accuracy: 0.8838 - val_loss: 0.3814\n",
            "Epoch 15/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.3478 - val_accuracy: 0.8838 - val_loss: 0.3710\n",
            "Epoch 16/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.3426 - val_accuracy: 0.8913 - val_loss: 0.3598\n",
            "Epoch 17/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.3159 - val_accuracy: 0.8906 - val_loss: 0.3473\n",
            "Epoch 18/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.3132 - val_accuracy: 0.8944 - val_loss: 0.3389\n",
            "Epoch 19/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2924 - val_accuracy: 0.8975 - val_loss: 0.3273\n",
            "Epoch 20/20\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.3125 - val_accuracy: 0.9031 - val_loss: 0.3208\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Accuracy: 0.90625\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           A       0.95      0.95      0.95       149\n",
            "           B       0.87      0.88      0.87       153\n",
            "           C       0.96      0.91      0.93       137\n",
            "           D       0.85      0.92      0.88       156\n",
            "           E       0.87      0.91      0.89       141\n",
            "           F       0.86      0.85      0.85       140\n",
            "           G       0.90      0.89      0.90       160\n",
            "           H       0.86      0.70      0.77       144\n",
            "           I       0.93      0.88      0.91       146\n",
            "           J       0.89      0.92      0.90       149\n",
            "           K       0.83      0.88      0.85       130\n",
            "           L       0.97      0.89      0.93       155\n",
            "           M       0.95      0.95      0.95       168\n",
            "           N       0.92      0.93      0.93       151\n",
            "           O       0.90      0.90      0.90       145\n",
            "           P       0.94      0.89      0.91       173\n",
            "           Q       0.96      0.95      0.96       166\n",
            "           R       0.78      0.87      0.82       160\n",
            "           S       0.89      0.92      0.91       171\n",
            "           T       0.91      0.93      0.92       163\n",
            "           U       0.94      0.92      0.93       183\n",
            "           V       0.90      0.94      0.92       158\n",
            "           W       0.92      0.97      0.94       148\n",
            "           X       0.93      0.97      0.95       154\n",
            "           Y       0.95      0.93      0.94       168\n",
            "           Z       0.95      0.89      0.92       132\n",
            "\n",
            "    accuracy                           0.91      4000\n",
            "   macro avg       0.91      0.90      0.91      4000\n",
            "weighted avg       0.91      0.91      0.91      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-tuner\n",
        "\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units1', min_value=32, max_value=128, step=32),\n",
        "                    activation=hp.Choice('act1', ['relu', 'tanh']),\n",
        "                    input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(units=hp.Int('units2', 32, 128, step=32),\n",
        "                    activation=hp.Choice('act2', ['relu', 'tanh'])))\n",
        "    model.add(Dense(26, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='ann_tuning',\n",
        "    project_name='alphabets'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=20, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate tuned model\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "y_pred_labels_tuned = np.argmax(y_pred_tuned, axis=1)\n",
        "\n",
        "print(\"\\nTuned Model Accuracy:\", accuracy_score(y_test, y_pred_labels_tuned))\n",
        "print(\"\\nTuned Classification Report:\\n\", classification_report(y_test, y_pred_labels_tuned, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogrDrKcQaCLI",
        "outputId": "bc85e51d-7091-4ea7-ee21-27a8e087ea44"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 32s]\n",
            "val_accuracy: 0.9506250023841858\n",
            "\n",
            "Best val_accuracy So Far: 0.9537500143051147\n",
            "Total elapsed time: 00h 05m 06s\n",
            "\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 53ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "Tuned Model Accuracy: 0.94775\n",
            "\n",
            "Tuned Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           A       0.98      0.99      0.98       149\n",
            "           B       0.90      0.92      0.91       153\n",
            "           C       0.98      0.94      0.96       137\n",
            "           D       0.94      0.96      0.95       156\n",
            "           E       0.91      0.94      0.93       141\n",
            "           F       0.93      0.92      0.93       140\n",
            "           G       0.93      0.95      0.94       160\n",
            "           H       0.87      0.85      0.86       144\n",
            "           I       0.90      0.97      0.94       146\n",
            "           J       1.00      0.93      0.97       149\n",
            "           K       0.86      0.95      0.90       130\n",
            "           L       0.98      0.94      0.96       155\n",
            "           M       0.97      0.97      0.97       168\n",
            "           N       0.98      0.93      0.95       151\n",
            "           O       0.93      0.97      0.95       145\n",
            "           P       0.99      0.94      0.96       173\n",
            "           Q       0.97      0.96      0.97       166\n",
            "           R       0.89      0.92      0.90       160\n",
            "           S       0.98      0.94      0.96       171\n",
            "           T       0.95      0.96      0.96       163\n",
            "           U       0.98      0.96      0.97       183\n",
            "           V       0.94      0.95      0.94       158\n",
            "           W       0.97      0.99      0.98       148\n",
            "           X       0.97      0.98      0.97       154\n",
            "           Y       0.97      0.95      0.96       168\n",
            "           Z       0.97      0.96      0.97       132\n",
            "\n",
            "    accuracy                           0.95      4000\n",
            "   macro avg       0.95      0.95      0.95      4000\n",
            "weighted avg       0.95      0.95      0.95      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtlIpiTDaRUd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}